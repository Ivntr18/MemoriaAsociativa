{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from theano import tensor as T\n",
    "from joblib import Parallel, delayed\n",
    "from matplotlib import cm\n",
    "import matplotlib as mpl\n",
    "from mnist import load_mnist\n",
    "from convnet import init_weights, RMSprop, convnet_model\n",
    "from associative import AssociativeMemory, AssociativeMemoryError\n",
    "%matplotlib inline\n",
    "\n",
    "mnist_path = './mnist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "trX, teX, trY, teY = load_mnist(mnist_path)\n",
    "trX = trX.reshape(-1, 1, 28, 28)\n",
    "teX = teX.reshape(-1, 1, 28, 28)\n",
    "\n",
    "X = T.ftensor4()\n",
    "Y = T.fmatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup of the training and testing.\n",
    "# Do not run this cell if you already have the weights of the network. \n",
    "\n",
    "w1 = init_weights((32, 1, 3, 3))\n",
    "w2 = init_weights((64, 32, 3, 3))\n",
    "w3 = init_weights((128, 64, 3, 3))\n",
    "w4 = init_weights((128 * 3 * 3, 625))\n",
    "w5 = init_weights((625, 10))\n",
    "\n",
    "# model with dropout ('n'oisy outputs)\n",
    "n_l1, n_l2, n_l3, n_l4, n_py_x = convnet_model(X, w1, w2, w3, w4, w5, 0.2, 0.5)\n",
    "\n",
    "# cost function\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(n_py_x, Y))\n",
    "params = [w1, w2, w3, w4, w5]\n",
    "updates = RMSprop(cost, params, lr=0.001)\n",
    "\n",
    "# Train function\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "\n",
    "# model without dropout\n",
    "l1, l2, l3, l4, py_x = convnet_model(X, w1, w2, w3, w4, w5, 0., 0.)\n",
    "y_x = T.argmax(py_x, axis=1)\n",
    "predict = theano.function(inputs=[X], outputs=y_x, allow_input_downcast=True)\n",
    "\n",
    "# Train the network\n",
    "for i in range(100):\n",
    "    for start, end in zip(range(0, len(trX), 128), range(128, len(trX), 128)):\n",
    "        cost = train(trX[start:end], trY[start:end])\n",
    "    print('Testing epoch number: {0}'.format(i))\n",
    "    print(np.mean(np.argmax(teY, axis=1) == predict(teX)))\n",
    "\n",
    "# Save the weights of the network\n",
    "\n",
    "\n",
    "np.save('w1.npy', w1.get_value())\n",
    "np.save('w2.npy', w2.get_value())\n",
    "np.save('w3.npy', w3.get_value())\n",
    "np.save('w4.npy', w4.get_value())\n",
    "np.save('w5.npy', w5.get_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the network's parameters to generate the features\n",
    "# Do not run this cell if you already generated the features. Skip to the next cell\n",
    "\n",
    "# Shared variables\n",
    "w1 = theano.shared(np.load('w1.npy'), name='w1')\n",
    "w2 = theano.shared(np.load('w2.npy'), name='w2')\n",
    "w3 = theano.shared(np.load('w3.npy'), name='w3')\n",
    "w4 = theano.shared(np.load('w4.npy'), name='w4')\n",
    "w5 = theano.shared(np.load('w5.npy'), name='w5')\n",
    "\n",
    "# model\n",
    "l1, l2, l3, l4, py_x = convnet_model(X, w1, w2, w3, w4, w5, 0., 0.)\n",
    "\n",
    "generate = theano.function(inputs=[X], outputs=l4, allow_input_downcast=True)\n",
    "\n",
    "# Generate features from the network\n",
    "\n",
    "train_features = np.zeros((60000, (128*3*3)), theano.config.floatX)\n",
    "\n",
    "for start, end in zip(range(0, len(trX), 200), range(200, (len(trX) + 1), 200)):\n",
    "    print(start, end)\n",
    "    batch = generate(trX[start:end])\n",
    "    train_features[start:end] = batch\n",
    "    \n",
    "np.save('train_features_l4.npy', train_features)\n",
    "\n",
    "test_features = np.zeros((10000, (128*3*3)), theano.config.floatX)\n",
    "\n",
    "for start, end in zip(range(0, len(teX), 200), range(200, (len(teX) + 1), 200)):\n",
    "    print(start, end)\n",
    "    batch = generate(teX[start:end])\n",
    "    test_features[start:end] = batch\n",
    "    \n",
    "np.save('test_features_l4.npy', test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the features\n",
    "\n",
    "train_X = np.load('train_features_l4.npy')\n",
    "test_X = np.load('test_features_l4.npy')\n",
    "trX, teX, trY, teY = load_mnist(mnist_path, onehot=False)\n",
    "# The ranges of all the memories that will be trained\n",
    "sizes = (1, 2, 4, 8, 16, 32, 64, 128, 256, 512)\n",
    "# the domain size. The size of the output layer of the network\n",
    "domain = 625\n",
    "# Maximum value of the features in the train set\n",
    "max_val = train_X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the different co-domain memories\n",
    "\n",
    "tables = np.zeros((len(sizes), 10, 5), dtype=np.float64)\n",
    "entropies = np.zeros((len(sizes), 10), dtype=np.float64)\n",
    "\n",
    "def get_ams_results(i, s, domain, train_X, test_X, trY, teY):\n",
    "    table = np.zeros((10, 5), dtype=np.float64)\n",
    "    entropy = np.zeros((10, ), dtype=np.float64)\n",
    "    ams = dict.fromkeys(range(10))\n",
    "    for j in ams:\n",
    "        # Create the memories with domain 's'\n",
    "        ams[j] = AssociativeMemory(domain, s)\n",
    "    # Round the values\n",
    "    train_X_around = np.around(train_X * (s - 1) / max_val).astype(np.int16)\n",
    "    test_X_around = np.around(test_X * (s - 1) / max_val).astype(np.int16)\n",
    "    # Abstraction\n",
    "    for x, y in zip(train_X_around, trY):\n",
    "        ams[y].abstract(x, input_range=s)\n",
    "    # Calculate entropies\n",
    "    for j in ams:\n",
    "        entropy[j] = ams[j].entropy\n",
    "    # Reduction\n",
    "    for x, y in zip(test_X_around, teY):\n",
    "        table[y, 0] += 1\n",
    "        for k in ams:\n",
    "            try:\n",
    "                ams[k].reduce(x, input_range=s)\n",
    "                if k == y:\n",
    "                    table[y, 1] += 1\n",
    "                else:\n",
    "                    table[y, 2] += 1\n",
    "                # confusion_mat[k, y] += 1\n",
    "            except AssociativeMemoryError:\n",
    "                if k != y:\n",
    "                    table[y, 3] += 1\n",
    "                else:\n",
    "                    table[y, 4] += 1\n",
    "    return (i, table, entropy)\n",
    "\n",
    "list_tables_entropies = Parallel(n_jobs=3, verbose=50)(\n",
    "    delayed(get_ams_results)(i, s, domain, train_X, test_X, trY, teY) for i, s in enumerate(sizes))\n",
    "\n",
    "for i, table, entropy in list_tables_entropies:\n",
    "    tables[i, :, :] = table\n",
    "    entropies[i, :] = entropy\n",
    "\n",
    "# Table columns\n",
    "# 0.- Total count\n",
    "# 1.- Able to reduce and it is the same number\n",
    "# 2.- Able to reduce and it is not the same number\n",
    "# 3.- Not able to reduce and it is not the same number\n",
    "# 4.- Not able to reduce and it is the same number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the precision and recall\n",
    "\n",
    "precision = np.zeros((len(sizes), 11, 1), dtype=np.float64)\n",
    "recall = np.zeros((len(sizes), 11, 1), dtype=np.float64)\n",
    "\n",
    "for i, s in enumerate(sizes):\n",
    "    prec_aux = tables[i, :, 1] / (tables[i, :, 1] + tables[i, :, 2])\n",
    "    recall_aux = tables[i, :, 1] / tables[i, :, 0]\n",
    "    precision[i, 0:10, 0] = prec_aux[:]\n",
    "    precision[i, 10, 0] = prec_aux.mean()\n",
    "    recall[i, 0:10, 0] = recall_aux[:]\n",
    "    recall[i, 10, 0] = recall_aux.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of precision and recall with entropies\n",
    "\n",
    "average_entropy = entropies.mean(axis=1)\n",
    "# Percentage\n",
    "average_precision = precision[:, 10, :] * 100\n",
    "average_recall = recall[:, 10, :] * 100\n",
    "\n",
    "# Setting up a colormap that's a simple transtion\n",
    "cmap = mpl.colors.LinearSegmentedColormap.from_list('mycolors',['cyan','purple'])\n",
    "\n",
    "# Using contourf to provide my colorbar info, then clearing the figure\n",
    "Z = [[0,0],[0,0]]\n",
    "step = 0.1\n",
    "levels = np.arange(0.0, 90 + step, step)\n",
    "CS3 = plt.contourf(Z, levels, cmap=cmap)\n",
    "plt.clf()\n",
    "\n",
    "\n",
    "plt.plot(np.arange(0, 100, 10), average_precision, 'r-o', label='Precision')\n",
    "plt.plot(np.arange(0, 100, 10), average_recall, 'b-s', label='Recall')\n",
    "plt.xlim(-0.1, 91)\n",
    "plt.ylim(0, 102)\n",
    "plt.xticks(np.arange(0, 100, 10), sizes)\n",
    "\n",
    "plt.xlabel('Range Quantization Levels')\n",
    "plt.ylabel('Percentage [%]')\n",
    "plt.legend(loc=4)\n",
    "plt.grid(True)\n",
    "\n",
    "entropy_labels = [str(e) for e in np.around(average_entropy, decimals=1)]\n",
    "\n",
    "cbar = plt.colorbar(CS3, orientation='horizontal')\n",
    "cbar.set_ticks(np.arange(0, 100, 10))\n",
    "cbar.ax.set_xticklabels(entropy_labels)\n",
    "cbar.set_label('Entropy')\n",
    "\n",
    "plt.savefig('graph_l4.png', dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
