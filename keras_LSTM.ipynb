{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Author: Ivan Torres-Rodriguez --- IIMAS UNAM\n",
    "#email: ivantr18@hotmail.com\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "import keras\n",
    "#from tensorflow.keras import backend as K\n",
    "from keras.layers import *\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 22\n",
    "epochs = 25\n",
    "img_rows, img_cols = 1, 1\n",
    "np.random.seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=np.load('T22Audio/feat_X.npy')\n",
    "#Y=np.load('T22Audio/feat_Y.npy')\n",
    "X=np.load('DIMEX100/Features/feat_X.npy')\n",
    "Y=np.load('DIMEX100/Features/feat_Y.npy')\n",
    "#X=np.array(rawX[:,:img_rows * img_cols], dtype='float32')\n",
    "#Prev=np.load('T22Audio/prevL.npy')\n",
    "Prev=np.load('DIMEX100/Features/prevL.npy')\n",
    "#Zeros=X==0\n",
    "#offset=X.min()\n",
    "#X=X-X.min()\n",
    "#X[Zeros]=0\n",
    "#X=X.reshape(X.shape[0],img_rows, img_cols)\n",
    "dicY={'a':0,'b':1,'d':2,'e':3,'f':4,'g':5,'i':6,'k':7,'l':8,'m':9,'n':10,'n~':11,'o':12,'p':13,'r':14,'r(':15,'s':16,'t':17,'tS':18,'u':19,'x':20,'Z':21}\n",
    "dicPrev={'-':-1,'a':0,'b':1,'d':2,'e':3,'f':4,'g':5,'i':6,'k':7,'l':8,'m':9,'n':10,'n~':11,'o':12,'p':13,'r':14,'r(':15,'s':16,'t':17,'tS':18,'u':19,'x':20,'Z':21}\n",
    "Y=[dicY[key] for key in Y]\n",
    "Y=np.array(Y, dtype='uint8')\n",
    "Prev=[dicPrev[key] for key in Prev]\n",
    "Prev=np.array(Prev, dtype='uint8')\n",
    "Prev=Prev+1\n",
    "sizeInp=X.shape[0]\n",
    "permutation = np.random.permutation(sizeInp)\n",
    "X=X[permutation]\n",
    "Y=Y[permutation]\n",
    "Prev=Prev[permutation]\n",
    "X=sequence.pad_sequences(X)\n",
    "#normalizacion\n",
    "#mean=X.mean()\n",
    "#std=X.std()\n",
    "#X=X-mean\n",
    "#X=X/std\n",
    "X=X-X.min()\n",
    "X=X/X.max()\n",
    "img_cols=X.shape[1]\n",
    "\n",
    "\n",
    "x_train=X[:int(0.9*sizeInp)]\n",
    "x_test=X[int(0.9*sizeInp):]\n",
    "y_train=Y[:int(0.9*sizeInp)]\n",
    "y_test=Y[int(0.9*sizeInp):]\n",
    "Prev_te=Prev[int(0.9*sizeInp):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "#x_train /= X.max()\n",
    "#x_test /= X.max()\n",
    "\n",
    "#Save y_train/test before onehot encoding\n",
    "np.save('T22Audio/train_features_Y.npy',y_train)\n",
    "np.save('T22Audio/test_features_Y.npy',y_test)\n",
    "np.save('T22Audio/test_prev.npy',Prev_te)\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(100, kernel_size=(3, 3),padding='same' ,activation='relu',input_shape=input_shape))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Conv2D(200, kernel_size=(3, 3), padding='same',activation='relu'))\n",
    "model.add(keras.layers.Conv2D(400, kernel_size=(3, 3), padding='same',activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#model.add(keras.layers.Dropout(0.25))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(650, activation='relu'))\n",
    "#model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 500\n",
    "input_shape=(X.shape[1],)\n",
    "\n",
    "def Conv():\n",
    "    model_lstm = Sequential()\n",
    "    model_lstm.add(Embedding(img_cols, embed_dim,input_length = X.shape[1]))\n",
    "    model_lstm.add(LSTM(lstm_out))\n",
    "    #print(model_lstm.summary())\n",
    "    return model_lstm\n",
    "\n",
    "\n",
    "def FCN():\n",
    "    model_fc = Sequential()\n",
    "    model_fc.add(Dense(num_classes, activation='softmax'))\n",
    "    #input_net = Input(shape=(lstm_out,))  # adapt this if using `channels_first` image data format   \n",
    "    return model_fc\n",
    "\n",
    "x = Input(shape=(input_shape))\n",
    "modelFCN=FCN()\n",
    "modelConv=Conv()\n",
    "# make the model:\n",
    "model = Model(x, modelFCN(modelConv(x)))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(keras.optimizers.Adam(lr=0.001),\n",
    "model.compile(keras.optimizers.Adam(),\n",
    "              loss=keras.losses.categorical_crossentropy,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('T22Audio/test_features_X.npy',modelConv.predict(x_test))\n",
    "np.save('T22Audio/train_features_X.npy',modelConv.predict(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ite=0\n",
    "##Get data\n",
    "test_X=np.load('T22Audio/test_features_X.npy')\n",
    "train_X=np.load('T22Audio/train_features_X.npy')\n",
    "teY=np.load('T22Audio/test_features_Y.npy')\n",
    "trY=np.load('T22Audio/train_features_Y.npy')\n",
    "\n",
    "\n",
    "\n",
    "    # The ranges of all the memories that will be trained\n",
    "sizes = (1, 2, 4, 8, 16, 32, 64, 128, 256, 512)\n",
    "    # the domain size. The size of the output layer of the network\n",
    "domain = 650\n",
    "    # the number of categories\n",
    "catN=22\n",
    "    # Maximum value of the features in the train set\n",
    "    #max_val = train_X.max()\n",
    "\n",
    "    # Train the different co-domain memories\n",
    "    \n",
    "tables = np.zeros((len(sizes), catN, 5), dtype=np.float64)\n",
    "entropies = np.zeros((len(sizes), int(catN)), dtype=np.float64)\n",
    "\n",
    "\n",
    "print('Train the different co-domain memories -----',ite)\n",
    "        #for i, s in enumerate(sizes):\n",
    "            #list_tables_entropies=get_ams_results1(i, s, domain, train_X, test_X, trY, teY)\n",
    "list_tables_entropies = Parallel(n_jobs=8, verbose=50)(\n",
    "    delayed(get_ams_results1)(i, s, domain, train_X, test_X, trY, teY) for i, s in enumerate(sizes))\n",
    "\n",
    "for i, table, entropy in list_tables_entropies:\n",
    "    tables[i, :, :] = table\n",
    "    entropies[i, :] = entropy\n",
    "    \n",
    "np.save('T22Audio/tables.npy', tables)\n",
    "np.save('T22Audio/entropies.npy', entropies)\n",
    "\n",
    "    # Table columns\n",
    "    # 0.- Total count\n",
    "    # 1.- Able to reduce and it is the same number\n",
    "    # 2.- Able to reduce and it is not the same number\n",
    "    # 3.- Not able to reduce and it is not the same number\n",
    "    # 4.- Not able to reduce and it is the same number\n",
    "\n",
    "    ##########################################################################################\n",
    "\n",
    "    # Calculate the precision and recall\n",
    "\n",
    "print('Calculate the precision and recall')\n",
    "precision = np.zeros((len(sizes), catN+1, 1), dtype=np.float64)\n",
    "recall = np.zeros((len(sizes), catN+1, 1), dtype=np.float64)\n",
    "\n",
    "for i, s in enumerate(sizes):\n",
    "    prec_aux = tables[i, :, 1] / (tables[i, :, 1] + tables[i, :, 2])\n",
    "    recall_aux = tables[i, :, 1] / tables[i, :, 0]\n",
    "    precision[i, 0:catN, 0] = prec_aux[:]\n",
    "    precision[i, catN, 0] = prec_aux.mean()\n",
    "    recall[i, 0:catN, 0] = recall_aux[:]\n",
    "    recall[i, catN, 0] = recall_aux.mean()\n",
    "    \n",
    "\n",
    "    ######################################################################################\n",
    "\n",
    "    # Plot of precision and recall with entropies\n",
    "\n",
    "print('Plot of precision and recall with entropies-----{0}'.format(ite))\n",
    "average_entropy.append( entropies.mean(axis=1) )\n",
    "    # Percentage\n",
    "average_precision.append( precision[:, catN, :] * 100 )\n",
    "average_recall.append( recall[:, catN, :] * 100 )\n",
    "    \n",
    "np.save('average_precision.npy', average_precision)\n",
    "np.save('average_recall.npy', average_recall)\n",
    "np.save('average_entropy.npy', average_entropy)\n",
    "    \n",
    "print('avg precision: ',average_precision[ite])\n",
    "print('avg recall: ',average_recall[ite])\n",
    "print('avg entropy: ',average_entropy[ite])\n",
    "\n",
    "    # Setting up a colormap that's a simple transtion\n",
    "cmap = mpl.colors.LinearSegmentedColormap.from_list('mycolors',['cyan','purple'])\n",
    "\n",
    "    # Using contourf to provide my colorbar info, then clearing the figure\n",
    "Z = [[0,0],[0,0]]\n",
    "step = 0.1\n",
    "levels = np.arange(0.0, 90 + step, step)\n",
    "CS3 = plt.contourf(Z, levels, cmap=cmap)\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "\n",
    "plt.plot(np.arange(0, 100, 10), average_precision[ite], 'r-o', label='Precision')\n",
    "plt.plot(np.arange(0, 100, 10), average_recall[ite], 'b-s', label='Recall')\n",
    "plt.xlim(-0.1, 91)\n",
    "plt.ylim(0, 102)\n",
    "plt.xticks(np.arange(0, 100, 10), sizes)\n",
    "\n",
    "plt.xlabel('Range Quantization Levels')\n",
    "plt.ylabel('Percentage [%]')\n",
    "plt.legend(loc=4)\n",
    "plt.grid(True)\n",
    "\n",
    "entropy_labels = [str(e) for e in np.around(average_entropy[ite], decimals=1)]\n",
    "\n",
    "cbar = plt.colorbar(CS3, orientation='horizontal')\n",
    "cbar.set_ticks(np.arange(0, 100, 10))\n",
    "cbar.ax.set_xticklabels(entropy_labels)\n",
    "cbar.set_label('Entropy')\n",
    "\n",
    "plt.savefig('T22Audio/graph_T22_{0}.png'.format(ite), dpi=500)\n",
    "print('Iteration {0} complete'.format(ite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array([[1,2,3,4,5,6],[7,8,9,10,11,12],[13,14,15,16,17,18],[19,20,21,22,23,24]])\n",
    "Y=np.array([[25,26,27,28,29,30],[31,32,33,34,35,36],[37,38,39,40,41,42],[43,44,45,46,47,48]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "L=[]\n",
    "X=X.flatten()\n",
    "Y=Y.flatten()\n",
    "L.append(X)\n",
    "L.append(Y)\n",
    "L=np.array(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 24)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "L=L.reshape(L.shape[0],4,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "newL=[]\n",
    "for element in L:\n",
    "    newL.append(element.T)\n",
    "newL=np.array(newL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 6, 4)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X=np.load('T22Audio/test_features_X.npy')\n",
    "train_X=np.load('T22Audio/train_features_X.npy')\n",
    "teY=np.load('T22Audio/test_features_Y.npy')\n",
    "trY=np.load('T22Audio/train_features_Y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1980534e-05"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
