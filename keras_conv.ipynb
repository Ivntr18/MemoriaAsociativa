{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 22\n",
    "epochs = 25\n",
    "img_rows, img_cols = 1, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=np.load('T22Audio/feat_X.npy')\n",
    "#Y=np.load('T22Audio/feat_Y.npy')\n",
    "X=np.load('DIMEX100/Features/feat_X.npy')\n",
    "Y=np.load('DIMEX100/Features/feat_Y.npy')\n",
    "#X=np.array(rawX[:,:img_rows * img_cols], dtype='float32')\n",
    "#Prev=np.load('T22Audio/prevL.npy')\n",
    "Prev=np.load('DIMEX100/Features/prevL.npy')\n",
    "#Zeros=X==0\n",
    "#offset=X.min()\n",
    "#X=X-X.min()\n",
    "#X[Zeros]=0\n",
    "#X=X.reshape(X.shape[0],img_rows, img_cols)\n",
    "dicY={'a':0,'b':1,'d':2,'e':3,'f':4,'g':5,'i':6,'k':7,'l':8,'m':9,'n':10,'n~':11,'o':12,'p':13,'r':14,'r(':15,'s':16,'t':17,'tS':18,'u':19,'x':20,'Z':21}\n",
    "dicPrev={'-':-1,'a':0,'b':1,'d':2,'e':3,'f':4,'g':5,'i':6,'k':7,'l':8,'m':9,'n':10,'n~':11,'o':12,'p':13,'r':14,'r(':15,'s':16,'t':17,'tS':18,'u':19,'x':20,'Z':21}\n",
    "Y=[dicY[key] for key in Y]\n",
    "Y=np.array(Y, dtype='uint8')\n",
    "Prev=[dicPrev[key] for key in Prev]\n",
    "Prev=np.array(Prev, dtype='uint8')\n",
    "Prev=Prev+1\n",
    "sizeInp=X.shape[0]\n",
    "permutation = np.random.permutation(sizeInp)\n",
    "X=X[permutation]\n",
    "Y=Y[permutation]\n",
    "Prev=Prev[permutation]\n",
    "#normalizacion\n",
    "mean=X.mean()\n",
    "std=X.std()\n",
    "X=X-mean\n",
    "X=X/std\n",
    "\n",
    "x_train=X[:int(0.9*sizeInp)]\n",
    "x_test=X[int(0.9*sizeInp):]\n",
    "y_train=Y[:int(0.9*sizeInp)]\n",
    "y_test=Y[int(0.9*sizeInp):]\n",
    "Prev_te=Prev[int(0.9*sizeInp):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  9, 17, ...,  6, 16, 17], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_cols)\n",
    "    input_shape = (1, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_cols, 1)\n",
    "    input_shape = (img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "#x_train /= X.max()\n",
    "#x_test /= X.max()\n",
    "\n",
    "#Save y_train/test before onehot encoding\n",
    "np.save('T22Audio/train_features_Y.npy',y_train)\n",
    "np.save('T22Audio/test_features_Y.npy',y_test)\n",
    "np.save('T22Audio/test_prev.npy',Prev_te)\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(100, kernel_size=(3, 3),padding='same' ,activation='relu',input_shape=input_shape))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Conv2D(200, kernel_size=(3, 3), padding='same',activation='relu'))\n",
    "model.add(keras.layers.Conv2D(400, kernel_size=(3, 3), padding='same',activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#model.add(keras.layers.Dropout(0.25))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(650, activation='relu'))\n",
    "#model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv():\n",
    "    input_img = Input(shape=(input_shape))  # adapt this if using `channels_first` image data format   \n",
    "    #e1 = Conv2D(16, (3, 3),strides=(2, 2), activation='relu', padding='valid')(input_img)\n",
    "    #e2 = MaxPooling2D(pool_size=(2, 2), padding='same')(e1)\n",
    "    #e3 = Conv2D(32, (3, 3), activation='relu', padding='same')(e2)\n",
    "    #e4 = MaxPooling2D(pool_size=(2, 2), padding='same')(e3)\n",
    "    #e5 = Dropout(rate=0.5, noise_shape=None, seed=None)(e4)\n",
    "    #e6 = Conv2D(128, (3, 3), activation='relu', padding='same')(e5)\n",
    "    #e7 = Dropout(rate=0.5, noise_shape=None, seed=None)(e6)\n",
    "    #e6 = MaxPooling2D(pool_size=(2, 2), padding='same')(e5)\n",
    "    e6 = Flatten()(input_img)\n",
    "    e7 = Dense(2400,activation=None)(e6)\n",
    "    #e8 = BatchNormalization()(e7)\n",
    "    e9 = Activation(\"relu\")(e7)\n",
    "    e10 = Dense(5000, activation='relu')(e6)\n",
    "    e11 = Dense(600, activation='relu')(e10)\n",
    "    e12 = Dropout(rate=0.5, noise_shape=None, seed=None)(e11)\n",
    "    return Model(input_img, e12)\n",
    "\n",
    "\n",
    "def FCN():\n",
    "    input_net = Input(shape=(600,))  # adapt this if using `channels_first` image data format   \n",
    "    d1 = Dense(num_classes, activation='softmax')(input_net)\n",
    "    return Model(input_net, d1)\n",
    "\n",
    "x = Input(shape=(input_shape))\n",
    "modelFCN=FCN()\n",
    "modelConv=Conv()\n",
    "# make the model:\n",
    "model = Model(x, modelFCN(modelConv(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(keras.optimizers.Adam(lr=0.001),\n",
    "model.compile(keras.optimizers.Adam(),\n",
    "              loss=keras.losses.categorical_crossentropy,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 208144 samples, validate on 23128 samples\n",
      "Epoch 1/25\n",
      "208144/208144 [==============================] - 7s 34us/step - loss: 1.9525 - acc: 0.3363 - val_loss: 1.8247 - val_acc: 0.3647\n",
      "Epoch 2/25\n",
      "208144/208144 [==============================] - 6s 30us/step - loss: 1.8511 - acc: 0.3658 - val_loss: 1.7816 - val_acc: 0.3802\n",
      "Epoch 3/25\n",
      "208144/208144 [==============================] - 6s 30us/step - loss: 1.8260 - acc: 0.3752 - val_loss: 1.7638 - val_acc: 0.3875\n",
      "Epoch 4/25\n",
      "208144/208144 [==============================] - 6s 30us/step - loss: 1.8115 - acc: 0.3794 - val_loss: 1.7708 - val_acc: 0.3840\n",
      "Epoch 5/25\n",
      "208144/208144 [==============================] - 6s 30us/step - loss: 1.8037 - acc: 0.3819 - val_loss: 1.7493 - val_acc: 0.3922\n",
      "Epoch 6/25\n",
      "208144/208144 [==============================] - 6s 30us/step - loss: 1.7943 - acc: 0.3843 - val_loss: 1.7649 - val_acc: 0.3819\n",
      "Epoch 7/25\n",
      "208144/208144 [==============================] - 6s 31us/step - loss: 1.7888 - acc: 0.3853 - val_loss: 1.7479 - val_acc: 0.3907\n",
      "Epoch 8/25\n",
      "208144/208144 [==============================] - 6s 31us/step - loss: 1.7826 - acc: 0.3874 - val_loss: 1.7373 - val_acc: 0.3922\n",
      "Epoch 9/25\n",
      "208144/208144 [==============================] - 6s 30us/step - loss: 1.7781 - acc: 0.3895 - val_loss: 1.7483 - val_acc: 0.3907\n",
      "Epoch 10/25\n",
      "208144/208144 [==============================] - 6s 30us/step - loss: 1.7762 - acc: 0.3899 - val_loss: 1.7334 - val_acc: 0.3987\n",
      "Epoch 11/25\n",
      "208144/208144 [==============================] - 6s 30us/step - loss: 1.7728 - acc: 0.3919 - val_loss: 1.7317 - val_acc: 0.3956\n",
      "Epoch 12/25\n",
      "208144/208144 [==============================] - 6s 30us/step - loss: 1.7695 - acc: 0.3931 - val_loss: 1.7387 - val_acc: 0.3955\n",
      "Epoch 13/25\n",
      "208144/208144 [==============================] - 6s 30us/step - loss: 1.7668 - acc: 0.3928 - val_loss: 1.7599 - val_acc: 0.3844\n",
      "Epoch 14/25\n",
      "208144/208144 [==============================] - 6s 30us/step - loss: 1.7628 - acc: 0.3944 - val_loss: 1.7179 - val_acc: 0.4025\n",
      "Epoch 15/25\n",
      "208144/208144 [==============================] - 6s 30us/step - loss: 1.7606 - acc: 0.3950 - val_loss: 1.7314 - val_acc: 0.4003\n",
      "Epoch 16/25\n",
      "208144/208144 [==============================] - 6s 30us/step - loss: 1.7589 - acc: 0.3955 - val_loss: 1.7260 - val_acc: 0.4033\n",
      "Epoch 17/25\n",
      "208144/208144 [==============================] - 6s 31us/step - loss: 1.7573 - acc: 0.3955 - val_loss: 1.7210 - val_acc: 0.4041\n",
      "Epoch 18/25\n",
      "208144/208144 [==============================] - 6s 31us/step - loss: 1.7548 - acc: 0.3971 - val_loss: 1.7125 - val_acc: 0.4052\n",
      "Epoch 19/25\n",
      "208144/208144 [==============================] - 6s 30us/step - loss: 1.7532 - acc: 0.3980 - val_loss: 1.7197 - val_acc: 0.4030\n",
      "Epoch 20/25\n",
      "208144/208144 [==============================] - 6s 30us/step - loss: 1.7517 - acc: 0.3977 - val_loss: 1.7218 - val_acc: 0.4009\n",
      "Epoch 21/25\n",
      "208144/208144 [==============================] - 6s 30us/step - loss: 1.7465 - acc: 0.3996 - val_loss: 1.7144 - val_acc: 0.4024\n",
      "Epoch 22/25\n",
      "208144/208144 [==============================] - 6s 30us/step - loss: 1.7479 - acc: 0.3985 - val_loss: 1.7252 - val_acc: 0.3980\n",
      "Epoch 23/25\n",
      "208144/208144 [==============================] - 6s 30us/step - loss: 1.7460 - acc: 0.3988 - val_loss: 1.7145 - val_acc: 0.4040\n",
      "Epoch 24/25\n",
      "208144/208144 [==============================] - 6s 30us/step - loss: 1.7454 - acc: 0.3997 - val_loss: 1.7064 - val_acc: 0.4056\n",
      "Epoch 25/25\n",
      "208144/208144 [==============================] - 6s 30us/step - loss: 1.7425 - acc: 0.4002 - val_loss: 1.7145 - val_acc: 0.4032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3bd18aca20>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('T22Audio/test_features_X.npy',modelConv.predict(x_test))\n",
    "np.save('T22Audio/train_features_X.npy',modelConv.predict(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ite=0\n",
    "##Get data\n",
    "test_X=np.load('T22Audio/test_features_X.npy')\n",
    "train_X=np.load('T22Audio/train_features_X.npy')\n",
    "teY=np.load('T22Audio/test_features_Y.npy')\n",
    "trY=np.load('T22Audio/train_features_Y.npy')\n",
    "\n",
    "\n",
    "\n",
    "    # The ranges of all the memories that will be trained\n",
    "sizes = (1, 2, 4, 8, 16, 32, 64, 128, 256, 512)\n",
    "    # the domain size. The size of the output layer of the network\n",
    "domain = 650\n",
    "    # the number of categories\n",
    "catN=22\n",
    "    # Maximum value of the features in the train set\n",
    "    #max_val = train_X.max()\n",
    "\n",
    "    # Train the different co-domain memories\n",
    "    \n",
    "tables = np.zeros((len(sizes), catN, 5), dtype=np.float64)\n",
    "entropies = np.zeros((len(sizes), int(catN)), dtype=np.float64)\n",
    "\n",
    "\n",
    "print('Train the different co-domain memories -----',ite)\n",
    "        #for i, s in enumerate(sizes):\n",
    "            #list_tables_entropies=get_ams_results1(i, s, domain, train_X, test_X, trY, teY)\n",
    "list_tables_entropies = Parallel(n_jobs=8, verbose=50)(\n",
    "    delayed(get_ams_results1)(i, s, domain, train_X, test_X, trY, teY) for i, s in enumerate(sizes))\n",
    "\n",
    "for i, table, entropy in list_tables_entropies:\n",
    "    tables[i, :, :] = table\n",
    "    entropies[i, :] = entropy\n",
    "    \n",
    "np.save('T22Audio/tables.npy', tables)\n",
    "np.save('T22Audio/entropies.npy', entropies)\n",
    "\n",
    "    # Table columns\n",
    "    # 0.- Total count\n",
    "    # 1.- Able to reduce and it is the same number\n",
    "    # 2.- Able to reduce and it is not the same number\n",
    "    # 3.- Not able to reduce and it is not the same number\n",
    "    # 4.- Not able to reduce and it is the same number\n",
    "\n",
    "    ##########################################################################################\n",
    "\n",
    "    # Calculate the precision and recall\n",
    "\n",
    "print('Calculate the precision and recall')\n",
    "precision = np.zeros((len(sizes), catN+1, 1), dtype=np.float64)\n",
    "recall = np.zeros((len(sizes), catN+1, 1), dtype=np.float64)\n",
    "\n",
    "for i, s in enumerate(sizes):\n",
    "    prec_aux = tables[i, :, 1] / (tables[i, :, 1] + tables[i, :, 2])\n",
    "    recall_aux = tables[i, :, 1] / tables[i, :, 0]\n",
    "    precision[i, 0:catN, 0] = prec_aux[:]\n",
    "    precision[i, catN, 0] = prec_aux.mean()\n",
    "    recall[i, 0:catN, 0] = recall_aux[:]\n",
    "    recall[i, catN, 0] = recall_aux.mean()\n",
    "    \n",
    "\n",
    "    ######################################################################################\n",
    "\n",
    "    # Plot of precision and recall with entropies\n",
    "\n",
    "print('Plot of precision and recall with entropies-----{0}'.format(ite))\n",
    "average_entropy.append( entropies.mean(axis=1) )\n",
    "    # Percentage\n",
    "average_precision.append( precision[:, catN, :] * 100 )\n",
    "average_recall.append( recall[:, catN, :] * 100 )\n",
    "    \n",
    "np.save('average_precision.npy', average_precision)\n",
    "np.save('average_recall.npy', average_recall)\n",
    "np.save('average_entropy.npy', average_entropy)\n",
    "    \n",
    "print('avg precision: ',average_precision[ite])\n",
    "print('avg recall: ',average_recall[ite])\n",
    "print('avg entropy: ',average_entropy[ite])\n",
    "\n",
    "    # Setting up a colormap that's a simple transtion\n",
    "cmap = mpl.colors.LinearSegmentedColormap.from_list('mycolors',['cyan','purple'])\n",
    "\n",
    "    # Using contourf to provide my colorbar info, then clearing the figure\n",
    "Z = [[0,0],[0,0]]\n",
    "step = 0.1\n",
    "levels = np.arange(0.0, 90 + step, step)\n",
    "CS3 = plt.contourf(Z, levels, cmap=cmap)\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "\n",
    "plt.plot(np.arange(0, 100, 10), average_precision[ite], 'r-o', label='Precision')\n",
    "plt.plot(np.arange(0, 100, 10), average_recall[ite], 'b-s', label='Recall')\n",
    "plt.xlim(-0.1, 91)\n",
    "plt.ylim(0, 102)\n",
    "plt.xticks(np.arange(0, 100, 10), sizes)\n",
    "\n",
    "plt.xlabel('Range Quantization Levels')\n",
    "plt.ylabel('Percentage [%]')\n",
    "plt.legend(loc=4)\n",
    "plt.grid(True)\n",
    "\n",
    "entropy_labels = [str(e) for e in np.around(average_entropy[ite], decimals=1)]\n",
    "\n",
    "cbar = plt.colorbar(CS3, orientation='horizontal')\n",
    "cbar.set_ticks(np.arange(0, 100, 10))\n",
    "cbar.ax.set_xticklabels(entropy_labels)\n",
    "cbar.set_label('Entropy')\n",
    "\n",
    "plt.savefig('T22Audio/graph_T22_{0}.png'.format(ite), dpi=500)\n",
    "print('Iteration {0} complete'.format(ite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
